{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL WORKING CODE\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T10:22:27.286445Z",
     "iopub.status.busy": "2025-04-24T10:22:27.285546Z",
     "iopub.status.idle": "2025-04-24T10:22:49.239136Z",
     "shell.execute_reply": "2025-04-24T10:22:49.238563Z",
     "shell.execute_reply.started": "2025-04-24T10:22:27.286414Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 10:22:37.636752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745490157.830610      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745490157.892165      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# 1. Enhanced Document Processing\n",
    "def load_documents():\n",
    "    documents = []\n",
    "    pdf_folder = \"/kaggle/input/rag-test\"\n",
    "    \n",
    "    for file in os.listdir(pdf_folder):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            try:\n",
    "                loader = PyPDFLoader(os.path.join(pdf_folder, file))\n",
    "                documents.extend(loader.load_and_split())\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {str(e)}\")\n",
    "    \n",
    "    # Better text splitting for legal documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=100,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"à¥¤ \", \"Â§\", \"(a)\", \"(b)\"]\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# 2. Fixed Pipeline Configuration\n",
    "def create_qa_chain():\n",
    "    model_name = \"google/flan-t5-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda:0\")\n",
    "\n",
    "    # Correct generation parameters\n",
    "    pipe = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=0,\n",
    "        max_length=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=40,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # Improved prompts\n",
    "    question_prompt = PromptTemplate(\n",
    "        template=\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer in simple Hindi/English:\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    combine_prompt = PromptTemplate(\n",
    "        template=\"Combine these answers clearly:\\n{summaries}\\n\\nFinal Question: {question}\\nDetailed Answer:\",\n",
    "        input_variables=[\"summaries\", \"question\"]\n",
    "    )\n",
    "\n",
    "    # Create vector store\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        load_documents(),\n",
    "        HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    )\n",
    "\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=HuggingFacePipeline(pipeline=pipe),\n",
    "        chain_type=\"map_reduce\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        chain_type_kwargs={\n",
    "            \"question_prompt\": question_prompt,\n",
    "            \"combine_prompt\": combine_prompt,\n",
    "            \"combine_document_variable_name\": \"summaries\"\n",
    "        },\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "# 3. Smarter Answer Formatting\n",
    "def farmer_friendly_answer(result):\n",
    "    answer = result['result'].strip()\n",
    "    \n",
    "    # Check for empty answers\n",
    "    if not answer or len(answer) < 20:\n",
    "        return \"Please visit your nearest Krishi Seva Kendra for details or Call KISAN CALL CENTER Toll Free No.1800-180-1551\"\n",
    "    \n",
    "    # Simplify technical terms\n",
    "    replacements = {\n",
    "        \"Sponsor\": \"Company\",\n",
    "        \"agreement\": \"contract\",\n",
    "        \"permanent structure\": \"permanent building\",\n",
    "        \"temporary modification\": \"temporary change\"\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        answer = answer.replace(old, new)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Query Interface\n",
    "def ask_farmer(query):\n",
    "    qa = create_qa_chain()\n",
    "    result = qa({\"query\": query})\n",
    "    \n",
    "    print(\"\\nðŸŒ¾\" + \"=\"*50 + \"ðŸŒ¾\")\n",
    "    print(f\"Question: {query}\")\n",
    "    print(\"ðŸŒ±\" + \"-\"*50 + \"ðŸŒ±\")\n",
    "    print(\"Answer:\", farmer_friendly_answer(result))\n",
    "    print(\"\\nRelevant Sources:\")\n",
    "    for doc in result['source_documents']:\n",
    "        print(f\"â€¢ {os.path.basename(doc.metadata['source'])} (Page {doc.metadata['page']+1})\")\n",
    "    print(\"ðŸŒ¾\" + \"=\"*50 + \"ðŸŒ¾\\n\")\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    ask_farmer(\"Can companies build permanent buildings on my land?\")\n",
    "    ask_farmer(\"What is the farming agreement act?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ask_farmer(\"What is the complete process outlined for resolving disputes between farmers and sponsors?\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7219633,
     "sourceId": 11513046,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
